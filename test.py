# Streamlit ë…ì„œ ê¸°ë¡ & ë¶„ì„ ì•±
# -------------------------------------------------
# í•„ìš”í•œ íŒ¨í‚¤ì§€
# pip install streamlit pandas requests wordcloud matplotlib pillow python-dateutil
# ì‹¤í–‰: streamlit run streamlit_book_log_app.py
# -------------------------------------------------

from __future__ import annotations
import io
import json
from datetime import datetime
from dateutil.relativedelta import relativedelta
from typing import Dict, Any, List, Optional

import requests
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from PIL import Image

st.set_page_config(page_title="ë…ì„œ ê¸°ë¡ & ë¶„ì„", page_icon="ğŸ“š", layout="wide")

# -----------------------------
# ìœ í‹¸
# -----------------------------

def _today_str():
    return datetime.today().strftime("%Y-%m-%d")

@st.cache_data(show_spinner=False)
def search_google_books(query: str, max_results: int = 10) -> List[Dict[str, Any]]:
    url = "https://www.googleapis.com/books/v1/volumes"
    params = {"q": query, "maxResults": max_results}
    r = requests.get(url, params=params, timeout=15)
    r.raise_for_status()
    data = r.json()
    items = data.get("items", [])
    results = []
    for it in items:
        info = it.get("volumeInfo", {})
        ids = info.get("industryIdentifiers", [])
        isbn10 = next((i.get("identifier") for i in ids if i.get("type") == "ISBN_10"), None)
        isbn13 = next((i.get("identifier") for i in ids if i.get("type") == "ISBN_13"), None)
        image_links = info.get("imageLinks", {})
        results.append({
            "source": "GoogleBooks",
            "id": it.get("id"),
            "title": info.get("title"),
            "subtitle": info.get("subtitle"),
            "authors": ", ".join(info.get("authors", [])),
            "publisher": info.get("publisher"),
            "publishedDate": info.get("publishedDate"),
            "pageCount": info.get("pageCount"),
            "categories": ", ".join(info.get("categories", [])),
            "language": info.get("language"),
            "isbn_10": isbn10,
            "isbn_13": isbn13,
            "thumbnail": image_links.get("thumbnail") or image_links.get("smallThumbnail"),
            "infoLink": info.get("infoLink") or it.get("selfLink"),
        })
    return results

@st.cache_data(show_spinner=False)
def search_open_library(query: str, limit: int = 10) -> List[Dict[str, Any]]:
    url = "https://openlibrary.org/search.json"
    params = {"q": query, "limit": limit}
    r = requests.get(url, params=params, timeout=15)
    r.raise_for_status()
    data = r.json()
    docs = data.get("docs", [])
    results = []
    for d in docs:
        cover_id = d.get("cover_i")
        isbn_list = d.get("isbn", [])
        isbn10 = next((i for i in isbn_list if len(i) == 10), None)
        isbn13 = next((i for i in isbn_list if len(i) == 13), None)
        categories = d.get("subject", [])
        results.append({
            "source": "OpenLibrary",
            "id": d.get("key"),
            "title": d.get("title"),
            "subtitle": None,
            "authors": ", ".join(d.get("author_name", []) or []),
            "publisher": ", ".join(d.get("publisher", [])[:1]) if d.get("publisher") else None,
            "publishedDate": str(d.get("first_publish_year")) if d.get("first_publish_year") else None,
            "pageCount": d.get("number_of_pages_median"),
            "categories": ", ".join(categories[:5]) if categories else None,
            "language": None,
            "isbn_10": isbn10,
            "isbn_13": isbn13,
            "thumbnail": f"https://covers.openlibrary.org/b/id/{cover_id}-M.jpg" if cover_id else None,
            "infoLink": f"https://openlibrary.org{d.get('key')}" if d.get("key") else None,
        })
    return results

# ISBN ë‹¨ì¼ ì¡°íšŒ (Google Books ìš°ì„ )
@st.cache_data(show_spinner=False)
def lookup_by_isbn(isbn: str) -> List[Dict[str, Any]]:
    isbn = isbn.replace("-", " ").strip()
    # Try Google Books first
    google = search_google_books(f"isbn:{isbn}", max_results=1)
    if google:
        return google
    # Fallback to Open Library
    ol = search_open_library(f"isbn:{isbn}", limit=1)
    return ol

# ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ
if "library" not in st.session_state:
    st.session_state.library = pd.DataFrame(columns=[
        "title", "authors", "publisher", "publishedDate", "pageCount", "categories",
        "isbn_10", "isbn_13", "language", "infoLink", "thumbnail", "date_read", "notes", "source"
    ])

# -----------------------------
# ì‚¬ì´ë“œë°”: ë°ì´í„° ê´€ë¦¬
# -----------------------------
with st.sidebar:
    st.header("âš™ï¸ ë°ì´í„° ê´€ë¦¬")
    uploaded = st.file_uploader("CSV ë¶ˆëŸ¬ì˜¤ê¸°", type=["csv"], help="ì´ì „ì— ì €ì¥í•œ ë…ì„œ ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
    if uploaded is not None:
        try:
            df_new = pd.read_csv(uploaded)
            # í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë³´ê°•
            for col in st.session_state.library.columns:
                if col not in df_new.columns:
                    df_new[col] = None
            # ìˆœì„œ ë§ì¶”ê¸°
            df_new = df_new[st.session_state.library.columns]
            st.session_state.library = df_new
            st.success("CSVë¥¼ ë¶ˆëŸ¬ì™”ì–´ìš”!")
        except Exception as e:
            st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    if not st.session_state.library.empty:
        csv = st.session_state.library.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ’¾ CSVë¡œ ë‚´ë³´ë‚´ê¸°", data=csv, file_name="reading_log.csv", mime="text/csv")

    st.markdown("---")
    st.caption("ë°ì´í„°ëŠ” ë¸Œë¼ìš°ì € ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤. í•„ìš”ì‹œ CSVë¡œ ì €ì¥í•´ë‘ì„¸ìš”.")

# -----------------------------
# ë©”ì¸: ì œëª©
# -----------------------------
st.title("ğŸ“š ë…ì„œ ê¸°ë¡ & ë¶„ì„")
st.caption("Open Library / Google Books APIë¡œ ë©”íƒ€ë°ì´í„° ìë™ ì±„ìš°ê¸° Â· ì¶”ì´ ê·¸ë˜í”„ Â· ì¥ë¥´ ì›Œë“œí´ë¼ìš°ë“œ")

# -----------------------------
# ì±… ì¶”ê°€ ì„¹ì…˜
# -----------------------------
st.subheader("â• ì±… ì¶”ê°€í•˜ê¸°")
col_api, col_query = st.columns([1, 3])
with col_api:
    api_choice = st.radio("ê²€ìƒ‰ ì†ŒìŠ¤", ["Google Books", "Open Library", "ISBN"], horizontal=True)

with col_query:
    if api_choice == "ISBN":
        isbn_input = st.text_input("ISBNìœ¼ë¡œ ì¶”ê°€", placeholder="ì˜ˆ: 9788972756194")
        do_search = st.button("ì¡°íšŒ")
        if do_search and isbn_input:
            with st.spinner("ISBN ì¡°íšŒ ì¤‘..."):
                results = lookup_by_isbn(isbn_input)
    else:
        query = st.text_input("ì œëª©/ì €ì/í‚¤ì›Œë“œë¡œ ê²€ìƒ‰", placeholder="ì˜ˆ: í•˜ë£¨í‚¤, ì‘ì€ ì•„ì”¨ë“¤, AI ethics")
        max_n = st.slider("ê²€ìƒ‰ ê°œìˆ˜", 1, 20, 10)
        do_search = st.button("ê²€ìƒ‰")
        results = []
        if do_search and query:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                if api_choice == "Google Books":
                    results = search_google_books(query, max_results=max_n)
                else:
                    results = search_open_library(query, limit=max_n)

if do_search:
    if results:
        st.success(f"{len(results)}ê±´ ì°¾ì•˜ì–´ìš”. ì•„ë˜ì—ì„œ ì„ íƒí•´ ì¶”ê°€í•˜ì„¸ìš”.")
        for i, r in enumerate(results):
            with st.expander(f"{i+1}. {r.get('title')} â€” {r.get('authors')}"):
                cols = st.columns([1,3])
                with cols[0]:
                    if r.get("thumbnail"):
                        try:
                            st.image(r["thumbnail"], use_container_width=True)
                        except Exception:
                            st.write(":grey[ì´ë¯¸ì§€ ë¶ˆê°€]")
                    else:
                        st.write(":grey[í‘œì§€ ì´ë¯¸ì§€ ì—†ìŒ]")
                with cols[1]:
                    meta_cols = {
                        "ì œëª©": r.get("title"),
                        "ë¶€ì œ": r.get("subtitle"),
                        "ì €ì": r.get("authors"),
                        "ì¶œíŒì‚¬": r.get("publisher"),
                        "ì¶œê°„": r.get("publishedDate"),
                        "ìª½ìˆ˜": r.get("pageCount"),
                        "ì¥ë¥´/ì¹´í…Œê³ ë¦¬": r.get("categories"),
                        "ISBN-10": r.get("isbn_10"),
                        "ISBN-13": r.get("isbn_13"),
                        "ì–¸ì–´": r.get("language"),
                        "ë§í¬": r.get("infoLink"),
                        "ì¶œì²˜": r.get("source"),
                    }
                    st.json({k: v for k, v in meta_cols.items() if v})

                    date_read = st.date_input("ì½ì€ ë‚ ì§œ", value=datetime.today())
                    notes = st.text_area("ë©”ëª¨", placeholder="ëŠë‚€ ì , ì¸ìƒ ê¹Šì€ ë¬¸ì¥ ë“±")
                    if st.button(f"ì´ ì±… ì¶”ê°€í•˜ê¸° #{i+1}"):
                        row = {
                            "title": r.get("title"),
                            "authors": r.get("authors"),
                            "publisher": r.get("publisher"),
                            "publishedDate": r.get("publishedDate"),
                            "pageCount": r.get("pageCount"),
                            "categories": r.get("categories"),
                            "isbn_10": r.get("isbn_10"),
                            "isbn_13": r.get("isbn_13"),
                            "language": r.get("language"),
                            "infoLink": r.get("infoLink"),
                            "thumbnail": r.get("thumbnail"),
                            "date_read": date_read.strftime("%Y-%m-%d"),
                            "notes": notes,
                            "source": r.get("source"),
                        }
                        st.session_state.library = pd.concat([
                            st.session_state.library,
                            pd.DataFrame([row])
                        ], ignore_index=True)
                        st.success("ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ 'ë‚´ ê¸°ë¡'ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ìš”. ê²€ìƒ‰ì–´/ISBNì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

st.markdown("---")

# -----------------------------
# ë‚´ ê¸°ë¡ (ë°ì´í„° í¸ì§‘)
# -----------------------------
st.subheader("ğŸ“– ë‚´ ê¸°ë¡ (í¸ì§‘ ê°€ëŠ¥)")

if st.session_state.library.empty:
    st.info("ì•„ì§ ì¶”ê°€ëœ ì±…ì´ ì—†ì–´ìš”. ìœ„ì—ì„œ ê²€ìƒ‰í•´ ì¶”ê°€í•´ ë³´ì„¸ìš”!")
else:
    # ë³´ê¸°/í¸ì§‘ í…Œì´ë¸”
    edited = st.data_editor(
        st.session_state.library,
        use_container_width=True,
        num_rows="dynamic",
        column_config={
            "title": st.column_config.TextColumn("ì œëª©", required=True),
            "authors": st.column_config.TextColumn("ì €ì"),
            "publisher": st.column_config.TextColumn("ì¶œíŒì‚¬"),
            "publishedDate": st.column_config.TextColumn("ì¶œê°„"),
            "pageCount": st.column_config.NumberColumn("ìª½ìˆ˜", step=1),
            "categories": st.column_config.TextColumn("ì¥ë¥´/ì¹´í…Œê³ ë¦¬"),
            "isbn_10": st.column_config.TextColumn("ISBN-10"),
            "isbn_13": st.column_config.TextColumn("ISBN-13"),
            "language": st.column_config.TextColumn("ì–¸ì–´"),
            "infoLink": st.column_config.LinkColumn("ì •ë³´ ë§í¬"),
            "thumbnail": st.column_config.TextColumn("í‘œì§€ URL"),
            "date_read": st.column_config.TextColumn("ì½ì€ ë‚ ì§œ (YYYY-MM-DD)"),
            "notes": st.column_config.TextColumn("ë©”ëª¨"),
            "source": st.column_config.TextColumn("ì¶œì²˜"),
        },
        hide_index=True,
    )
    st.session_state.library = edited

    # ê°„ë‹¨ í†µê³„
    stats1, stats2, stats3, stats4 = st.columns(4)
    with stats1:
        st.metric("ì´ ê¶Œìˆ˜", len(edited))
    with stats2:
        st.metric("ê³ ìœ  ì €ì ìˆ˜", edited["authors"].fillna("").apply(lambda s: [a.strip() for a in s.split(",") if a.strip()] ).explode().nunique())
    with stats3:
        pages = pd.to_numeric(edited["pageCount"], errors="coerce").dropna()
        st.metric("ì´ í˜ì´ì§€", int(pages.sum()) if len(pages) else 0)
    with stats4:
        this_year = str(datetime.today().year)
        st.metric("ì˜¬í•´ ì½ì€ ì±…", int((edited["date_read"].fillna("").str.startswith(this_year)).sum()))

st.markdown("---")

# -----------------------------
# ë¶„ì„ ëŒ€ì‹œë³´ë“œ
# -----------------------------
st.subheader("ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

if st.session_state.library.empty:
    st.info("ë°ì´í„°ê°€ ìˆì–´ì•¼ ë¶„ì„í•  ìˆ˜ ìˆì–´ìš”. ìœ„ì—ì„œ ì±…ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
else:
    df = st.session_state.library.copy()
    # ë‚ ì§œ íŒŒì‹±
    df["date_read_parsed"] = pd.to_datetime(df["date_read"], errors="coerce")

    # 1) ë…ì„œëŸ‰ ì¶”ì´ ê·¸ë˜í”„ (ì›”ë³„)
    st.markdown("#### ğŸ“Š ì›”ë³„ ë…ì„œëŸ‰ ì¶”ì´")
    # ìµœê·¼ 12ê°œì›” ë³´ê¸° í† ê¸€
    only_12 = st.toggle("ìµœê·¼ 12ê°œì›”ë§Œ ë³´ê¸°", value=True)
    ts = (
        df.dropna(subset=["date_read_parsed"]) 
          .assign(month=lambda x: x["date_read_parsed"].dt.to_period("M").dt.to_timestamp())
          .groupby("month").size().rename("count").reset_index()
          .sort_values("month")
    )
    if only_12 and not ts.empty:
        cutoff = datetime.today() - relativedelta(months=11)
        ts = ts[ts["month"] >= cutoff.replace(day=1)]

    if ts.empty:
        st.write(":grey[í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ì–´ìš”.]")
    else:
        fig1, ax1 = plt.subplots()
        ax1.plot(ts["month"], ts["count"], marker="o")
        ax1.set_xlabel("ì›”")
        ax1.set_ylabel("ê¶Œìˆ˜")
        ax1.set_title("ì›”ë³„ ì½ì€ ê¶Œìˆ˜")
        ax1.grid(True, linestyle=":", alpha=0.4)
        st.pyplot(fig1, use_container_width=True)

    st.markdown("---")

    # 2) ê°€ì¥ ë§ì´ ì½ì€ ì¥ë¥´ ì›Œë“œí´ë¼ìš°ë“œ
    st.markdown("#### â˜ï¸ ì¥ë¥´/ì¹´í…Œê³ ë¦¬ ì›Œë“œí´ë¼ìš°ë“œ")
    cats = df["categories"].dropna().astype(str)
    tokens: List[str] = []
    for c in cats:
        # ì¹´í…Œê³ ë¦¬ ë¬¸ìì—´ì„ ì‰¼í‘œ/ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„
        parts = [p.strip() for p in c.replace("/", ",").split(",") if p.strip()]
        tokens.extend(parts)
    if not tokens:
        st.write(":grey[ì¥ë¥´ ì •ë³´ê°€ ì—†ì–´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ë§Œë“¤ ìˆ˜ ì—†ì–´ìš”.]")
    else:
        freq = pd.Series(tokens).value_counts().to_dict()
        wc = WordCloud(width=1000, height=500, background_color="white")
        wc.generate_from_frequencies(freq)
        fig2, ax2 = plt.subplots(figsize=(10,5))
        ax2.imshow(wc, interpolation="bilinear")
        ax2.axis("off")
        st.pyplot(fig2, use_container_width=True)

    st.markdown("---")

    # 3) ì¶œíŒì‚¬/ì €ì TOP N
    st.markdown("#### ğŸ·ï¸ ê°€ì¥ ë§ì´ ì½ì€ ì €ì/ì¶œíŒì‚¬")
    top_n = st.slider("TOP N", 3, 15, 5, key="topn")

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ì €ì TOP**")
        authors_series = df["authors"].fillna("").apply(lambda s: [a.strip() for a in s.split(",") if a.strip()])
        top_authors = pd.Series([a for lst in authors_series for a in lst]).value_counts().head(top_n)
        if top_authors.empty:
            st.write(":grey[ë°ì´í„° ì—†ìŒ]")
        else:
            fig3, ax3 = plt.subplots()
            top_authors.sort_values().plot(kind="barh", ax=ax3)
            ax3.set_xlabel("ê¶Œìˆ˜")
            st.pyplot(fig3, use_container_width=True)

    with c2:
        st.markdown("**ì¶œíŒì‚¬ TOP**")
        top_pubs = df["publisher"].dropna().astype(str).value_counts().head(top_n)
        if top_pubs.empty:
            st.write(":grey[ë°ì´í„° ì—†ìŒ]")
        else:
            fig4, ax4 = plt.subplots()
            top_pubs.sort_values().plot(kind="barh", ax=ax4)
            ax4.set_xlabel("ê¶Œìˆ˜")
            st.pyplot(fig4, use_container_width=True)

# -----------------------------
# í‘¸í„°
# -----------------------------
st.markdown("---")
st.caption("Â© ë…ì„œ ê¸°ë¡ & ë¶„ì„ â€” Streamlit ì˜ˆì œ. Open Library ë° Google Books ë©”íƒ€ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

